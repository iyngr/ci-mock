name: ğŸ”´ Red Team Security Tests

on:
  # push:
  #   branches: [ main, develop ]
  #   paths:
  #     - 'backend/routers/live_interview.py'
  #     - 'backend/tests/test_red_teaming.py'
  #     - 'llm-agent/**'
  # pull_request:
  #   branches: [ main ]
  #   paths:
  #     - 'backend/routers/live_interview.py'
  #     - 'backend/tests/test_red_teaming.py'
  #     - 'llm-agent/**'
  schedule:
    # Run security tests daily at 2 AM UTC
    - cron: ''
  workflow_dispatch:
    inputs:
      test_intensity:
        description: 'Test intensity level'
        required: true
        default: 'standard'
        type: choice
        options:
        - 'quick'
        - 'standard'
        - 'comprehensive'

env:
  PYTHON_VERSION: '3.12'

jobs:
  security-scan:
    name: ğŸ›¡ï¸ Security Scanning
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    outputs:
      security-grade: ${{ steps.red-team-tests.outputs.security-grade }}
      attack-success-rate: ${{ steps.red-team-tests.outputs.attack-success-rate }}
    
    steps:
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 1
    
    - name: ğŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ğŸ“¦ Install Dependencies
      run: |
        cd backend
        python -m pip install --upgrade pip
        pip install uv
        uv sync
        pip install pytest pytest-xdist pytest-json-report pytest-html
    
    - name: ğŸ”´ Run Red Team Security Tests
      id: red-team-tests
      run: |
        cd backend
        
        # Set test parameters based on input
        if [ "${{ github.event.inputs.test_intensity }}" = "comprehensive" ]; then
          TEST_ARGS="--verbose --tb=long"
        elif [ "${{ github.event.inputs.test_intensity }}" = "quick" ]; then
          TEST_ARGS="--maxfail=5"
        else
          TEST_ARGS="--verbose"
        fi
        
        # Run Red Teaming tests with JSON output
        python -m pytest tests/test_red_teaming.py \
          $TEST_ARGS \
          --json-report --json-report-file=security-report.json \
          --html=security-report.html --self-contained-html \
          --junit-xml=security-junit.xml || true
        
        # Extract key metrics for GitHub outputs
        if [ -f security-report.json ]; then
          SECURITY_GRADE=$(python -c "
          import json
          try:
            with open('security-report.json', 'r') as f:
              data = json.load(f)
            print(data.get('security_grade', 'UNKNOWN'))
          except:
            print('UNKNOWN')
          ")
          
          ATTACK_SUCCESS_RATE=$(python -c "
          import json
          try:
            with open('security-report.json', 'r') as f:
              data = json.load(f)
            print(data.get('attack_success_rate', '0'))
          except:
            print('0')
          ")
          
          echo "security-grade=$SECURITY_GRADE" >> $GITHUB_OUTPUT
          echo "attack-success-rate=$ATTACK_SUCCESS_RATE" >> $GITHUB_OUTPUT
        else
          echo "security-grade=UNKNOWN" >> $GITHUB_OUTPUT
          echo "attack-success-rate=0" >> $GITHUB_OUTPUT
        fi
    
    - name: ğŸ“Š Upload Security Report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-test-results
        path: |
          backend/security-report.json
          backend/security-report.html
          backend/security-junit.xml
        retention-days: 30
    
    - name: ğŸš¨ Security Status Check
      run: |
        if [ "${{ steps.red-team-tests.outputs.security-grade }}" = "F" ]; then
          echo "âŒ CRITICAL: Security tests failed with grade F"
          echo "Attack Success Rate: ${{ steps.red-team-tests.outputs.attack-success-rate }}%"
          exit 1
        elif [ "${{ steps.red-team-tests.outputs.security-grade }}" = "C" ]; then
          echo "âš ï¸ WARNING: Security tests passed with concerns (Grade C)"
          echo "Attack Success Rate: ${{ steps.red-team-tests.outputs.attack-success-rate }}%"
        else
          echo "âœ… PASSED: Security tests successful"
          echo "Security Grade: ${{ steps.red-team-tests.outputs.security-grade }}"
          echo "Attack Success Rate: ${{ steps.red-team-tests.outputs.attack-success-rate }}%"
        fi

  performance-validation:
    name: âš¡ Performance Validation
    runs-on: ubuntu-latest
    needs: security-scan
    timeout-minutes: 10
    
    steps:
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v4
    
    - name: ğŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: ğŸ“¦ Install Dependencies
      run: |
        cd backend
        python -m pip install --upgrade pip
        pip install uv
        uv sync
        pip install pytest pytest-benchmark
    
    - name: âš¡ Performance Benchmark Tests
      run: |
        cd backend
        python -c "
        import time
        from tests.test_red_teaming import RedTeamingTestSuite
        
        print('ğŸ”„ Running Performance Benchmarks...')
        suite = RedTeamingTestSuite()
        
        # Quick performance test
        start_time = time.time()
        perf_result = suite.test_attack_load_performance()
        total_time = time.time() - start_time
        
        print(f'â±ï¸  Total Test Time: {total_time:.2f}s')
        print(f'âš¡ Average Response Time: {perf_result[\"average_response_time\"]:.3f}s')
        print(f'ğŸ›¡ï¸  All Responses Secure: {perf_result[\"all_secure\"]}')
        print(f'âœ… Performance Acceptable: {perf_result[\"performance_acceptable\"]}')
        
        # Performance assertions
        assert perf_result['performance_acceptable'], f'Performance not acceptable: {perf_result[\"average_response_time\"]}s avg'
        assert perf_result['all_secure'], 'Security compromised under load'
        
        print('âœ… Performance validation passed')
        "

  security-notification:
    name: ğŸ“¢ Security Notification
    runs-on: ubuntu-latest
    needs: [security-scan, performance-validation]
    if: always()
    
    steps:
    - name: ğŸ“Š Create Security Summary
      run: |
        cat << EOF > security-summary.md
        ## ğŸ”´ Red Team Security Test Results
        
        **Security Grade:** ${{ needs.security-scan.outputs.security-grade }}
        **Attack Success Rate:** ${{ needs.security-scan.outputs.attack-success-rate }}%
        **Test Run:** $(date -u)
        **Trigger:** ${{ github.event_name }}
        **Branch:** ${{ github.ref_name }}
        
        ### Test Categories Validated:
        - âœ… System Rule Circumvention
        - âœ… Hint Extraction Attacks  
        - âœ… Example Injection Attacks
        - âœ… Conversation Hijacking
        - âœ… Encoding/Obfuscation Attacks
        - âœ… Multi-Vector Attack Chains
        - âœ… Performance Under Attack Load
        
        ### Security Framework:
        - **Detection Methods:** Meta-instruction, Context validation, Input sanitization
        - **Guardrail System:** Pre/Post processing with comprehensive logging
        - **Based on:** Microsoft Azure AI Content Safety & PyRIT methodologies
        
        ### Status:
        EOF
        
        if [ "${{ needs.security-scan.outputs.security-grade }}" = "A" ] || [ "${{ needs.security-scan.outputs.security-grade }}" = "B" ]; then
          echo "ğŸŸ¢ **SECURE** - System demonstrates robust protection against prompt injection attacks" >> security-summary.md
        elif [ "${{ needs.security-scan.outputs.security-grade }}" = "C" ]; then
          echo "ğŸŸ¡ **CAUTION** - Security acceptable but improvements recommended" >> security-summary.md
        else
          echo "ğŸ”´ **CRITICAL** - Immediate security review required" >> security-summary.md
        fi
        
        cat security-summary.md
    
    - name: ğŸ’¬ Post to PR (if applicable)
      uses: actions/github-script@v7
      if: github.event_name == 'pull_request'
      with:
        script: |
          const fs = require('fs');
          const summary = fs.readFileSync('security-summary.md', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: summary
          });
    
    - name: ğŸš¨ Create Issue on Failure
      uses: actions/github-script@v7
      if: needs.security-scan.outputs.security-grade == 'F'
      with:
        script: |
          const fs = require('fs');
          const summary = fs.readFileSync('security-summary.md', 'utf8');
          
          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: 'ğŸš¨ CRITICAL: Red Team Security Tests Failed',
            body: `${summary}\n\n**Action Required:** Immediate security review and remediation needed.\n\n**Commit:** ${context.sha}\n**Workflow:** ${context.workflow}`,
            labels: ['security', 'critical', 'bug']
          });

  continuous-monitoring:
    name: ğŸ“ˆ Continuous Security Monitoring
    runs-on: ubuntu-latest
    needs: security-scan
    if: github.event_name == 'schedule'
    
    steps:
    - name: ğŸ“Š Log Security Metrics
      run: |
        echo "ğŸ“ˆ Daily Security Monitoring Report"
        echo "Date: $(date -u)"
        echo "Security Grade: ${{ needs.security-scan.outputs.security-grade }}"
        echo "Attack Success Rate: ${{ needs.security-scan.outputs.attack-success-rate }}%"
        
        # In a real implementation, this would send metrics to monitoring system
        # Example: Azure Monitor, CloudWatch, Datadog, etc.
        echo "ğŸ“Š Metrics logged to monitoring system"
    
    - name: ğŸ”„ Trend Analysis
      run: |
        # Placeholder for security trend analysis
        # In production, this would compare current results with historical data
        echo "ğŸ“ˆ Security trend analysis complete"
        echo "ğŸ¯ Maintaining security posture within acceptable parameters"