# Sample environment variables for llm-agent
# Copy to llm-agent/.env and fill with real values before running the service.

# Application
APP_NAME="Smart Mock AI Service"
APP_VERSION="0.1.0"
DEBUG=false
LOG_LEVEL=info
HOST=0.0.0.0
PORT=8000

# Sample environment variables for backend (FastAPI)
# Copy to backend/.env and fill with real values before running

# Cosmos DB (Azure) - endpoint for azure-cosmos client. This code uses DefaultAzureCredential by default.
# Example: https://<your-cosmos-account>.documents.azure.com:443/
# If you plan to use AAD auth locally, set these for DefaultAzureCredential (or sign-in via Azure CLI)
# AZURE_CLIENT_ID=
# AZURE_TENANT_ID=
# AZURE_CLIENT_SECRET=

# Azure OpenAI (preferred) - either API key auth OR Azure AD via DefaultAzureCredential
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-5-mini
# AZURE_OPENAI_MODEL removed; use AZURE_OPENAI_DEPLOYMENT_NAME (the Azure deployment name) only.
AZURE_OPENAI_API_VERSION=2025-01-01-preview
AZURE_OPENAI_EMBED_DEPLOYMENT=text-embedding-3-small


# RAG / Database (optional) - point to the same Cosmos DB as backend if RAG features required
COSMOS_DB_ENDPOINT=
COSMOS_DB_KEY=
DATABASE_NAME=

# RAG (Vector) COSMOS DB CONFIGURATION
RAG_COSMOS_DB_ENDPOINT=
RAG_COSMOS_DB_DATABASE=
RAG_COSMOS_DB_KEY=""

# Debug / console flags
DEBUG_MODE=false
CONSOLE_UI_ENABLED=false

# Integration with main backend
MAIN_API_ENDPOINT=http://localhost:8000
MAIN_API_KEY=

# Judge0 (if llm-agent calls or receives judge0 results)
JUDGE0_API_URL=
JUDGE0_API_KEY=

# Optional toggles
USE_MOCK_OPENAI=false

# Logging / Observability
AUTOGEN_ENABLE_TRACE_LOGGING=true
LOG_FILE_PATH=./logs/llm-agent.log